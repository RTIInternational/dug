#############################################################
##
## Dug is a semantic search pipeline framework including
##
##   Ingest:
##
##     link: Annotate a data set with ontology identifiers
##           based on NLP and other tagging mechanisms.
##       usage: bin/dug link <metadata>
##
##     load: Turn the data into a knowledge graph into a
##           graph and add insert it into a database. 
##       usage: bin/dug load <metadata>_tagged.json
##
##   Crawl & Index:
##
##     crawl: Execute graph queries against an aggregator.
##            Record the knowledge graphs in a cache.
##       usage: bin/dug crawl
##
##     index: Analyze the graph to build a search index.
##       usage: bin/dug index
##
##     query: Query the search engine from the command line
##       usage: bin/dug query <text>
##
##   Search:
##
##     api: Provides a REST API to the search engine.
##       bin/dug api [--debug] [--port=<int>]
##
#############################################################
#!/bin/bash

# Configure the PYTHONPATH
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
DUG_HOME=$( dirname $DIR )
export PYTHONPATH=$DUG_HOME:$DUG_HOME/kgx

# Ensure the KGX library is installed
if [ ! -d $DUG_HOME/kgx ]; then
    git clone https://github.com/NCATS-Tangerine/kgx.git $DUG_HOME/kgx
fi

# Development tools.
dev () {
    # This must be run once and only once before running the stack.
    DUGENV=$DUG_HOME/docker/.env    
    init () {
        HOSTNAME=$HOSTNAME RANDOM=$RANDOM envsubst < $DUG_HOME/docker/.env.template > $DUG_HOME/docker/.env
    }
    # This must be run each time before a component connects to the stack.
    conf ()  {
        if [ ! -f $DUGENV ]; then
            echo missing $DUGENV - will probably need that.
            return
        fi
        source $DUGENV
        export $(cut -d= -f1 $DUGENV)
    }
    $*
}
dev conf


### INGEST:

#############################################################
##
## Link: Generate linked data information from raw metadata.
##
#############################################################
link () {
    if [ $(echo "$*" | grep -c "_variables_") == 1 ]; then
        echo topmed tagged variables
        ELASTIC_API_HOST=localhost python -m  dug.ingest --tagged $*
    else
        echo annotate $*
        python -m dug.ingest --annotate $*
     fi        
}

#############################################################
##
## Load: Create a knowledge graph in a graph database.
##
#############################################################
load () {
    python -m dug.ingest --load $input $*
}

### Crawl/Index

#############################################################
##
## Crawl: Gather knowledge graphs via queries.
##
#############################################################
crawl () {
    curdir=$PWD
    cd $DUG_HOME/dug
    python -m dug.core --crawl $*
    cd $curdir
}

#############################################################
##
## Index: Create indices and add to search engine.
##
#############################################################
index () {
    curdir=$PWD
    cd $DUG_HOME/dug
    python -m dug.core --index $*
    cd $curdir
}

#############################################################
##
## Query: Test the created index with a query.
##
#############################################################
query () {
    python -m dug.core --query $*
}

#############################################################
##
## API: Run the OpenAPI search endpoint.
##
#############################################################
api () {
    python -m dug.api $*
}

#############################################################
##
## Stack: Start the system's essential persistence services.
##
#############################################################
stack () {
      docker-compose -f $DUG_HOME/docker/docker-compose.yaml up $*
}
#############################################################
##
## Test: Automated functional test
##
#############################################################
test () {

     # Prerequisites: stack must be running.
     # API must be running.

     # Delete the test index
     curl -X DELETE http://localhost:9200/test

     # Ingest, annotate, load knowledge graph.
     bin/dug link data/dd.xml
     bin/dug load data/dd_tagged.json

     # Crawl model queries, create index, test index.
     bin/dug crawl
     bin/dug index
     sleep 4
     bin/dug query coug # direct to search engine

     # Query via API
     bin/dug query_api coug
}
query_api () {
     query="`echo '{"index" : "test", "query" : { "match" : {"name": {"query" : "'$1'", "fuzziness" : 1 }}}}'`"
     curl --data "$query" \
           --header "Content-Type: application/json" \
           --request POST \
           http://localhost:5551/search
}

$*

exit 0
